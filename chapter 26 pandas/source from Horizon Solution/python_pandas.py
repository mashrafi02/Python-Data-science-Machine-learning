# -*- coding: utf-8 -*-
"""Python Pandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LJWNwUJBNBQeNBthToFvYG1XIdXSZtG7
"""

!pip install pandas

import pandas as pd

df_csv = pd.read_csv('/content/test.csv')

df_csv

df_excel = pd.read_excel('/content/sample.xls', sheet_name='Sheet1' )

df_excel

df_excel.shape

# Create a DataFrame from a dictionary
data_dict = {
    'column1': [1, 2, 3, 4],
    'column2': ['A', 'B', 'C', 'D']
}

df_dict = pd.DataFrame(data_dict)

df_dict

# Create a DataFrame from a list of tuples
data_list_of_tuples = [
    (1, 'A'),
    (2, 'B'),
    (3, 'C'),
    (4, 'D')
]

df_touples = pd.DataFrame(data_list_of_tuples, columns=['Column1', 'Column2'])

df_touples

# Create a DataFrame from a list of dictionaries
data_list_of_dicts = [
    {'column1': 1, 'column2': 'A'},
    {'column1': 2, 'column2': 'B'},
    {'column1': 3, 'column2': 'C'},
    {'column1': 4, 'column2': 'D'}
]

df_dict = pd.DataFrame(data_list_of_dicts)

df_dict

import pandas as pd

# Create a simple DataFrame
data = {
    'A': [10, 20, 30, 40, 50, 60],
    'B': [5.5, 6.5, 7.5, 8.5, 9.5, 10.5],
    'C': ['X', 'Y', 'Z', 'X', 'Y', 'Z']
}
df = pd.DataFrame(data)

# Display the DataFrame
print(df)

df.shape

df.head()

df.head(3)

df.tail(2)

df

(10+20+30+40+50+60)/6

df.min()

# Minimum value in each column
print(df.min(numeric_only=True))

# Maximum value in each column
print(df.max(numeric_only=True))

# Mean value of each column
print(df.mean(numeric_only=True))

# Standard deviation of each column
print(df.std(numeric_only=True))

# Summary statistics
print(df.describe())

print(df.info())

df

df[2:4]

df[['A','B']]

df

df.columns

# Selecting a specific cell using .loc
print(df.loc[2, 'B'])

import pandas as pd
import numpy as np

# Create a DataFrame with missing data
data = {
    'A': [1, 2, np.nan, 4, 5],
    'B': [np.nan, 2.5, 3.5, np.nan, 5.5],
    'C': ['a', 'b', np.nan, 'd', 'e']
}
df = pd.DataFrame(data)

df

# Selecting a specific cell using .iloc
print(df.iloc[0, 0])

fill_with_one=df.fillna(1)

fill_with_one

df.fillna(df.mean(numeric_only=True))

df

# Forward-fill NaN values
df.fillna(method='ffill')

df.fillna(method='bfill')

""" Dropna"""

import pandas as pd
import numpy as np

#create a dataframe with missing value

data = {
    'A' : [ 1, 2, np.nan, 4, 5],
    'B' : [np.nan, 2.5, 3.5, np.nan, 5.5],
    'C' : ['a', 'b', np.nan, 'd', 'e']
}

df = pd.DataFrame(data)


df

df_dropna_rows = df.dropna()

df_dropna_rows

#drop columns with any NaN values
df_dropna_cols = df.dropna(axis = 1)

df_dropna_cols

import pandas as pd
import numpy as np

#create a dataframe with missing value

data = {
    'A' : [ 1, 2, np.nan, 4, 5],
    'B' : [np.nan, 2.5, 3.5, np.nan, 5.5],
    'C' : ['a', 'b', np.nan, 'd', 'e']
}

df = pd.DataFrame(data)

print(df)

#drop rows where all are NAN

df_dropna_all_rows = df.dropna(how='all')

print("\nDrop rows where all values are NaN:\n", df_dropna_all_rows)

import pandas as pd
import numpy as np

# Create a DataFrame with missing data
data = {
    'A': [1, 2, np.nan, 4, 5],
    'B': [np.nan, 2.5, 3.5, np.nan, 5.5],
    'C': ['a', 'b', np.nan, 'd', 'e']
}
df = pd.DataFrame(data)

# Display the original DataFrame
print("Original DataFrame:\n", df)

#interpolate missing values using linear method

df_interpolated_linear = df.interpolate()

print("linear interpolate\n",df_interpolated_linear)

import pandas as pd
import numpy as np

# Create a DataFrame with missing data
data = {
    'A': [1, 2, np.nan, 4, 5],
    'B': [np.nan, 2.5, 3.5, np.nan, 5.5],
    'C': ['a', 'b', np.nan, 'd', 'e']
}
df = pd.DataFrame(data)

# Display the original DataFrame
print("Original DataFrame:\n", df)

df_replace = df.replace(np.nan, "missing")
print("dataframe with replace nans:\n",df_replace)

import pandas as pd
import numpy as np

# Create a DataFrame with special placeholder values
data = {
    'temperature': [25.0, 30.5, -999.9, 22.0, 28.0],
    'wind speed': [5, -999, 15, 10, -999],
    'event': ['Rain', 'Sunny', 'Missing', 'Cloudy', 'Sunny'],
    'description': ['Hot day', 'Very hot day', 'Cold day', 'Windy day', 'Rainy day'],
    'score': ['poor', 'average', 'good', 'exceptional', 'good']
}
df = pd.DataFrame(data)

# Display the original DataFrame
print("Original DataFrame:\n", df)

df_replace_single_value = df.replace(10, np.nan)
print("replace single value with nan",df_replace_single_value)

#Replace based on column
df_replaced_columns = df.replace({'temperature':30.5, 'wind speed':10,'event':'Missing'}, np.nan)
print(df_replaced_columns)

import pandas as pd
import numpy as np

# Create a DataFrame with special placeholder values
data = {
    'temperature': [25.0, 30.5, -999.9, 22.0, 28.0],
    'wind speed': [5, -999, 15, 10, -999],
    'event': ['Rain', 'Sunny', 'no event', 'Cloudy', 'Sunny'],
    'description': ['Hot day', 'Very hot day', 'Cold day', 'Windy day', 'Rainy day'],
    'score': ['poor', 'average', 'good', 'exceptional', 'good']
}
df = pd.DataFrame(data)

# Display the original DataFrame
print("Original DataFrame:\n", df)

#Replace value using mapping
df_replacing_mapping = df.replace({-999.9: np.nan, 'no event': 'Sunny','poor':'bad' })
print(df_replacing_mapping)

import pandas as pd
import numpy as np

# Create a DataFrame with special placeholder values
data = {
    'temperature': [25.0, 30.5, -999.9, 22.0, 28.0],
    'wind speed': [5, -999, 15, 10, -999],
    'event': ['Rain', 'Sunny', 'no event', 'Cloudy', 'Sunny'],
    'description': ['Hot day', 'Very hot day', 'Cold day', 'Windy day', 'Rainy day'],
    'score': ['poor', 'average', 'good', 'exceptional', 'good']
}
df = pd.DataFrame(data)

# Display the original DataFrame
print("Original DataFrame:\n", df)

#Replace list of values using a replacement map

replace_map = {'poor':1, 'average':2, 'good':3,'exceptional':4}
df['score'] = df['score'].replace(replace_map)

print("\nDataFrame with List of Values Replaced:\n", df)

import pandas as pd

# Sample employee data
data = {
    'EmployeeID': [101, 102, 103, 104, 105],
    'Name': ['John', 'Emma', 'Michael', 'Sophia', 'William'],
    'Department': ['HR', 'Marketing', 'Finance', 'IT', 'Operations'],
    'Salary': [60000, 70000, 80000, 90000, 65000],
    'ExperienceYears': [5, 3, 7, 4, 6]
}

df = pd.DataFrame(data)

print("Original DataFrame:\n", df)

#Rename columns
df.rename(columns={'Salary' : 'Monthlysalary', 'ExperienceYears':'YearsOfExperience'}, inplace = True)
print("\nDataFrame after Column Renaming:\n", df)

# Adding a new column for annual salary
df['AnnualSalary'] = df['Monthlysalary'] * 12
print("\nDataFrame with Annual Salary Column:\n", df)

#Dropping 'EEmployeeID' from dataframe
df.drop(columns = ['EmployeeID'], inplace = True)
print("\nDataFrame after Dropping 'EmployeeID' Column:\n", df)

#Filtering data for employees with salary 75000
high_salary_employess = df[df['Monthlysalary'] > 75000]
print("\nHigh Salary Employees:\n", high_salary_employess)

import pandas as pd

# Sample employee data
data = {
    'EmployeeID': [101, 102, 103, 104, 105],
    'Name': ['John', 'Emma', 'Michael', 'Sophia', 'William'],
    'Department': ['HR', 'Marketing', 'Finance', 'IT', 'Operations'],
    'Salary': [60000, 70000, 80000, 90000, 65000],
    'ExperienceYears': [5, 3, 7, 4, 6]
}

df = pd.DataFrame(data)

print("Original DataFrame:\n", df)

#Sorting data by years of experience in descending order
sorted_df = df.sort_values(by='ExperienceYears', ascending = False)
print("\nSorted DataFrame by Years of Experience:\n", sorted_df)

df['Department'] = df['Department'].replace({'HR':'Human Resources', 'IT': 'Infrormation Technology'})
print("\nDataFrame with Replaced Department Names:\n", df)

#applying a functionb a salary a column to convert to hourly rate
df['HourlyRate'] = df['Salary'].apply(lambda x: x / (4*40)) #Assuming 4 weeks and 40 hours per week
print("\nDataFrame with Hourly Rate column:\n",df)

import pandas as pd

# Sample employee data
data = {
    'EmployeeID': [101, 102, 103, 104, 105,106],
    'Name': ['John', 'Emma', 'Michael', 'Sophia','mahi', 'William'],
    'Department': ['HR', 'Marketing','Marketing', 'Finance', 'IT', 'Operations'],
    'Salary': [60000, 70000, 80000,85000, 90000, 65000],
    'ExperienceYears': [5, 3, 7, 4,6,6]
}

df = pd.DataFrame(data)

print("Original DataFrame:\n", df)

#Grouping by department and calculating average salary

avg_salary_by_department = df.groupby('Department')['Salary'].mean()
print("\nAverage salary by Deparment:\n",avg_salary_by_department)

#Introducing missing values

df.loc[2, 'Salary'] = None

print(df)

#filling missing valus with median salary

median_salary  = df['Salary'].median()
df['Salary'].fillna(median_salary, inplace = True)
print("\nDataFrame after Filling Missing Values:\n", df)

import pandas as pd

# Create first DataFrame
data1 = {
    'A': [1, 2, 3],
    'B': ['a', 'b', 'c']
}
df1 = pd.DataFrame(data1)

# Create second DataFrame
data2 = {
    'A': [4, 5, 6],
    'B': ['d', 'e', 'f']
}
df2 = pd.DataFrame(data2)

# Display the DataFrames
print("DataFrame 1:\n", df1)
print("\nDataFrame 2:\n", df2)

#simple concat along rows
df_concat = pd.concat([df1, df2])
print("\nSimple Concatenate:\n", df_concat)

import pandas as pd

# Create first DataFrame
data1 = {
    'A': [1, 2, 3],
    'B': ['a', 'b', 'c']
}
df1 = pd.DataFrame(data1)

# Create second DataFrame
data2 = {
    'A': [4, 5, 6],
    'B': ['d', 'e', 'f']
}
df2 = pd.DataFrame(data2)

# Display the DataFrames
print("DataFrame 1:\n", df1)
print("\nDataFrame 2:\n", df2)

#concatenate and ignore original index
df_concat_ignore_index = pd.concat([df1, df2], ignore_index = True)
print("\nConcatenate Ignoring Original Index:\n", df_concat_ignore_index)

#Concatenate along columns

df_concat_columns = pd.concat([df1,df2], axis=1)
print("\nConcatenate Along columns:\n", df_concat_columns)

#concatenate and set new index
df_concat_new_index = pd.concat([df1, df2]).reset_index(drop = True)
df_concat_new_index.index = ['row1','row2','row3','row4','row5','row6']

df_concat_new_index

"""Merge"""

import pandas as pd

df1 = pd.DataFrame({'key':['A','B','C'], 'value1':[1,2,3]})
df2 = pd.DataFrame({'key':['B','C','D'], 'value1':[4,5,6]})

result = pd.merge(df1, df2, on='key', how='inner')
print(result)

result = pd.merge(df1, df2, on='key', how='outer')
print(result)

import pandas as pd

df1 = pd.DataFrame({'key':['A','B','C'], 'value1':[1,2,3]})
df2 = pd.DataFrame({'key':['B','C','D'], 'value1':[4,5,6]})

result = pd.merge(df1, df2, on='key', how='left')
print(result)

result = pd.merge(df1, df2, on='key', how='right')
print(result)

"""### Shifting

shit up/down
"""

df = pd.DataFrame({'value': [1, 2, 3, 4,5]})

df

df['shifted'] = df['value'].shift(1)

df

"""Shift will fill"""

#shift up by 1 period

df['shift_reverse'] = df['value'].shift(-1)
df

df['shifted_value'] = df['value'].shift(1, fill_value = 0)
df



"""### Group by"""

import pandas as pd

# Sample data
data = {
    'City': ['Dhaka', 'Chittagong', 'Khulna', 'Rajshahi', 'Sylhet',
             'Dhaka', 'Chittagong', 'Khulna', 'Rajshahi', 'Sylhet'],
    'Population': [8906039, 2683447, 663342, 763952, 531663,
                   8906039, 2683447, 663342, 763952, 531663],
    'Area': [306.38, 168.07, 59.57, 96.68, 26.50,
             306.38, 168.07, 59.57, 96.68, 26.50],
    'Temperature': [30, 29, 28, 32, 31,
                    33, 34, 35, 29, 30]
}

df = pd.DataFrame(data)

# Display the DataFrame
print("Original DataFrame:\n", df)



#group by city and calculate mean  Population

mean_population = df.groupby('City')['Population'].mean()
print("\nMean Population by City:\n", mean_population)

#group by city and calculate mean of areas
mean_areas = df.groupby('City')['Area'].sum()
print("\nSum of Areas by City:\n",mean_areas)

mean_temperature = df.groupby('City')['Temperature'].mean()
print("\nMean temperature by City:\n", mean_temperature)

# Group by 'City' and aggregate multiple functions
agg_functions = df.groupby('City').agg({
    'Population': 'mean',
    'Area': 'sum',
    'Temperature': ['mean', 'max']
})

print("\nAggregated Data by City:\n", agg_functions)

# Sample data with 'Year'
data_with_year = {
    'City': ['Dhaka', 'Chittagong', 'Khulna', 'Rajshahi', 'Sylhet',
             'Dhaka', 'Chittagong', 'Khulna', 'Rajshahi', 'Sylhet'],
    'Year': [2023, 2023, 2023, 2023, 2023,
             2024, 2024, 2024, 2024, 2024],
    'Population': [8906039, 2683447, 663342, 763952, 531663,
                   8906039, 2683447, 663342, 763952, 531663],
    'Area': [306.38, 168.07, 59.57, 96.68, 26.50,
             306.38, 168.07, 59.57, 96.68, 26.50],
    'Temperature': [30, 29, 28, 32, 31,
                    33, 34, 35, 29, 30]
}

df_with_year = pd.DataFrame(data_with_year)

# Display the DataFrame with 'Year'
print("\nDataFrame with Year:\n", df_with_year)

#Group by city and year and calculate the mean temp

mean_temp_by_city_year = df_with_year.groupby(['City', 'Year'])['Temperature'].mean()
print(mean_temp_by_city_year)



